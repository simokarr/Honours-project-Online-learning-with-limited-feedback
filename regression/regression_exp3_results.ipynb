{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90b082-5df6-46ec-894f-f938126283b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model R² Score (Before Tuning): 0.8588\n",
      "\n",
      "Iteration 1/20\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 10\n",
      "Reward (R² Score): 0.8607\n",
      "New Best R² Score: 0.8607 with Parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 2/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 120\n",
      "Reward (R² Score): 0.8643\n",
      "New Best R² Score: 0.8643 with Parameters: {'n_estimators': 120, 'max_depth': 5, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 3/20\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 20\n",
      "Reward (R² Score): 0.8865\n",
      "New Best R² Score: 0.8865 with Parameters: {'n_estimators': 120, 'max_depth': 20, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 4/20\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': None\n",
      "Reward (R² Score): 0.8865\n",
      "\n",
      "Iteration 5/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 200\n",
      "Reward (R² Score): 0.8875\n",
      "New Best R² Score: 0.8875 with Parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 6/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 280\n",
      "Reward (R² Score): 0.8863\n",
      "\n",
      "Iteration 7/20\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': log2\n",
      "Reward (R² Score): 0.8581\n",
      "\n",
      "Iteration 8/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 130\n",
      "Reward (R² Score): 0.8864\n",
      "\n",
      "Iteration 9/20\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': sqrt\n",
      "Reward (R² Score): 0.8702\n",
      "\n",
      "Iteration 10/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 80\n",
      "Reward (R² Score): 0.8845\n",
      "\n",
      "Iteration 11/20\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 5\n",
      "Reward (R² Score): 0.8648\n",
      "\n",
      "Iteration 12/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 210\n",
      "Reward (R² Score): 0.8867\n",
      "\n",
      "Iteration 13/20\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 10\n",
      "Reward (R² Score): 0.8875\n",
      "\n",
      "Iteration 14/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 260\n",
      "Reward (R² Score): 0.8870\n",
      "\n",
      "Iteration 15/20\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': sqrt\n",
      "Reward (R² Score): 0.8702\n",
      "\n",
      "Iteration 16/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 70\n",
      "Reward (R² Score): 0.8833\n",
      "\n",
      "Iteration 17/20\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 30\n",
      "Reward (R² Score): 0.8872\n",
      "\n",
      "Iteration 18/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 100\n",
      "Reward (R² Score): 0.8860\n",
      "\n",
      "Iteration 19/20\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 70\n",
      "Reward (R² Score): 0.8833\n",
      "\n",
      "Iteration 20/20\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': None\n",
      "Reward (R² Score): 0.8875\n",
      "\n",
      "Best Hyperparameters Found:\n",
      "{'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 10, 'max_features': None}\n",
      "Best Validation R² Score: 0.8875\n",
      "\n",
      "Final Predictions vs. Actual Values:\n",
      "    Actual      Predicted\n",
      "0   154500  140161.039387\n",
      "1   325000  325361.522490\n",
      "2   115000  116985.445628\n",
      "3   159000  161448.039932\n",
      "4   315500  324579.807685\n",
      "5    75500   85895.446920\n",
      "6   311500  211714.853705\n",
      "7   146000  153898.463971\n",
      "8    84500   86433.190807\n",
      "9   135500  127795.625748\n",
      "10  145000  155826.093264\n",
      "11  130000  123031.757571\n",
      "12   81000  109844.283334\n",
      "13  214000  209537.295671\n",
      "14  181000  179102.479932\n",
      "15  134500  130427.465947\n",
      "16  183500  195378.622213\n",
      "17  135000  135605.259863\n",
      "18  118400  117531.106933\n",
      "19  226000  206985.938572\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define the EXP3 algorithm class\n",
    "class EXP3:\n",
    "    def __init__(self, n_arms, gamma=0.1):\n",
    "        self.n_arms = n_arms\n",
    "        self.gamma = gamma\n",
    "        self.weights = np.ones(n_arms)\n",
    "        \n",
    "    def select_arm(self):\n",
    "        total_weight = np.sum(self.weights)\n",
    "        probabilities = (\n",
    "            (1 - self.gamma) * (self.weights / total_weight) +\n",
    "            (self.gamma / self.n_arms)\n",
    "        )\n",
    "        arm = np.random.choice(self.n_arms, p=probabilities)\n",
    "        return arm, probabilities\n",
    "        \n",
    "    def update(self, chosen_arm, reward, probabilities):\n",
    "        x = reward / probabilities[chosen_arm]\n",
    "        self.weights[chosen_arm] *= np.exp((self.gamma * x) / self.n_arms)\n",
    "\n",
    "# Load the House Prices dataset\n",
    "data = pd.read_csv('train2.csv')\n",
    "\n",
    "# Preprocessing steps\n",
    "# Drop columns with too many missing values or irrelevant features\n",
    "data = data.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Handle missing values\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Impute numerical features with median\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X[numeric_features] = imputer_num.fit_transform(X[numeric_features])\n",
    "\n",
    "# Impute categorical features with mode\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_features] = imputer_cat.fit_transform(X[categorical_features])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the possible values for each hyperparameter with expanded search space\n",
    "hyperparameter_values = {\n",
    "    'n_estimators': list(range(50, 301, 10)),  # [50, 60, ..., 300]\n",
    "    'max_depth': [None] + list(range(5, 36, 5)),  # [None, 5, 10, ..., 35]\n",
    "    'min_samples_split': list(range(2, 21, 2)),  # [2, 4, ..., 20]\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize current hyperparameter values (starting point)\n",
    "current_params = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 2,\n",
    "    'max_features': None\n",
    "}\n",
    "\n",
    "# **New Section: Train and Evaluate the Initial Model**\n",
    "# Train the Random Forest model with the initial hyperparameters\n",
    "initial_model = RandomForestRegressor(\n",
    "    n_estimators=current_params['n_estimators'],\n",
    "    max_depth=current_params['max_depth'],\n",
    "    min_samples_split=current_params['min_samples_split'],\n",
    "    max_features=current_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "initial_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the initial model on the validation set\n",
    "initial_y_pred = initial_model.predict(X_valid)\n",
    "initial_r2 = r2_score(y_valid, initial_y_pred)\n",
    "print(f\"Initial Model R² Score (Before Tuning): {initial_r2:.4f}\")\n",
    "\n",
    "# Number of iterations for the hyperparameter tuning loop\n",
    "n_iterations = 20\n",
    "\n",
    "# Initialize the bandit algorithms for each hyperparameter\n",
    "bandits = {}\n",
    "for hp in hyperparameter_values:\n",
    "    n_arms = len(hyperparameter_values[hp])\n",
    "    bandits[hp] = {\n",
    "        'algorithm': EXP3(n_arms)\n",
    "    }\n",
    "\n",
    "# Initialize the bandit algorithm for hyperparameter selection\n",
    "hyperparameters = list(hyperparameter_values.keys())\n",
    "n_hyperparameters = len(hyperparameters)\n",
    "hyperparameter_bandit = EXP3(n_hyperparameters)\n",
    "\n",
    "# Map hyperparameter indices to names\n",
    "hyperparameter_indices = {idx: hp for idx, hp in enumerate(hyperparameters)}\n",
    "\n",
    "# Track the best model performance and parameters\n",
    "best_r2 = initial_r2  # Start with the initial R² score\n",
    "best_params = current_params.copy()\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "for i in range(n_iterations):\n",
    "    print(f\"\\nIteration {i+1}/{n_iterations}\")\n",
    "    \n",
    "    # Select which hyperparameter to adjust using the hyperparameter bandit\n",
    "    hp_arm_index, hp_probabilities = hyperparameter_bandit.select_arm()\n",
    "    hp_to_adjust = hyperparameter_indices[hp_arm_index]\n",
    "    \n",
    "    # Select the value for the chosen hyperparameter using its bandit algorithm\n",
    "    algorithm = bandits[hp_to_adjust]['algorithm']\n",
    "    arm_index, probabilities = algorithm.select_arm()\n",
    "    hp_value = hyperparameter_values[hp_to_adjust][arm_index]\n",
    "    \n",
    "    # Save the previous value to revert if necessary\n",
    "    previous_value = current_params[hp_to_adjust]\n",
    "    \n",
    "    # Update the current parameters with the new value\n",
    "    current_params[hp_to_adjust] = hp_value\n",
    "    \n",
    "    # Train the Random Forest model with the updated hyperparameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=current_params['n_estimators'],\n",
    "        max_depth=current_params['max_depth'],\n",
    "        min_samples_split=current_params['min_samples_split'],\n",
    "        max_features=current_params['max_features'],\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "    reward = r2  # Use R² score as the reward\n",
    "\n",
    "    # Update the bandit algorithm for the chosen hyperparameter value\n",
    "    algorithm.update(arm_index, reward, probabilities)\n",
    "    \n",
    "    # Update the hyperparameter selection bandit\n",
    "    hyperparameter_bandit.update(hp_arm_index, reward, hp_probabilities)\n",
    "    \n",
    "    # Print detailed output\n",
    "    print(f\"Adjusted Hyperparameter: {hp_to_adjust}\")\n",
    "    print(f\"Chosen Value for '{hp_to_adjust}': {hp_value}\")\n",
    "    print(f\"Reward (R² Score): {reward:.4f}\")\n",
    "    \n",
    "    # Check if the new configuration is better\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_params = current_params.copy()\n",
    "        print(f\"New Best R² Score: {best_r2:.4f} with Parameters: {best_params}\")\n",
    "    else:\n",
    "        # If not better, revert the hyperparameter change\n",
    "        current_params[hp_to_adjust] = previous_value\n",
    "\n",
    "# After the tuning loop, print the best hyperparameters and R² score\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(best_params)\n",
    "print(f\"Best Validation R² Score: {best_r2:.4f}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "final_predictions = final_model.predict(X_valid)\n",
    "\n",
    "# Compare final predictions with actual values\n",
    "final_comparison_df = pd.DataFrame({'Actual': y_valid.values, 'Predicted': final_predictions})\n",
    "print(\"\\nFinal Predictions vs. Actual Values:\")\n",
    "print(final_comparison_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a0bd4d-89a7-481a-8077-4285e5a38520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Model R² Score (Before Tuning): 0.8588\n",
      "\n",
      "Iteration 1/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 10\n",
      "Reward (R² Score): 0.8607\n",
      "New Best R² Score: 0.8607 with Parameters: {'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 2/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 130\n",
      "Reward (R² Score): 0.8644\n",
      "New Best R² Score: 0.8644 with Parameters: {'n_estimators': 130, 'max_depth': 5, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 3/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 6\n",
      "Reward (R² Score): 0.8617\n",
      "\n",
      "Iteration 4/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 90\n",
      "Reward (R² Score): 0.8638\n",
      "\n",
      "Iteration 5/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 20\n",
      "Reward (R² Score): 0.8864\n",
      "New Best R² Score: 0.8864 with Parameters: {'n_estimators': 130, 'max_depth': 20, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 6/50\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': log2\n",
      "Reward (R² Score): 0.8575\n",
      "\n",
      "Iteration 7/50\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': log2\n",
      "Reward (R² Score): 0.8575\n",
      "\n",
      "Iteration 8/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 25\n",
      "Reward (R² Score): 0.8867\n",
      "New Best R² Score: 0.8867 with Parameters: {'n_estimators': 130, 'max_depth': 25, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 9/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 120\n",
      "Reward (R² Score): 0.8868\n",
      "New Best R² Score: 0.8868 with Parameters: {'n_estimators': 120, 'max_depth': 25, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 10/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 220\n",
      "Reward (R² Score): 0.8871\n",
      "New Best R² Score: 0.8871 with Parameters: {'n_estimators': 220, 'max_depth': 25, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 11/50\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': sqrt\n",
      "Reward (R² Score): 0.8718\n",
      "\n",
      "Iteration 12/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 10\n",
      "Reward (R² Score): 0.8895\n",
      "New Best R² Score: 0.8895 with Parameters: {'n_estimators': 220, 'max_depth': 10, 'min_samples_split': 10, 'max_features': None}\n",
      "\n",
      "Iteration 13/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 25\n",
      "Reward (R² Score): 0.8871\n",
      "\n",
      "Iteration 14/50\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': sqrt\n",
      "Reward (R² Score): 0.8690\n",
      "\n",
      "Iteration 15/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 14\n",
      "Reward (R² Score): 0.8843\n",
      "\n",
      "Iteration 16/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 4\n",
      "Reward (R² Score): 0.8909\n",
      "New Best R² Score: 0.8909 with Parameters: {'n_estimators': 220, 'max_depth': 10, 'min_samples_split': 4, 'max_features': None}\n",
      "\n",
      "Iteration 17/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 14\n",
      "Reward (R² Score): 0.8843\n",
      "\n",
      "Iteration 18/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 20\n",
      "Reward (R² Score): 0.8921\n",
      "New Best R² Score: 0.8921 with Parameters: {'n_estimators': 220, 'max_depth': 20, 'min_samples_split': 4, 'max_features': None}\n",
      "\n",
      "Iteration 19/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 25\n",
      "Reward (R² Score): 0.8916\n",
      "\n",
      "Iteration 20/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 25\n",
      "Reward (R² Score): 0.8916\n",
      "\n",
      "Iteration 21/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 14\n",
      "Reward (R² Score): 0.8862\n",
      "\n",
      "Iteration 22/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 10\n",
      "Reward (R² Score): 0.8909\n",
      "\n",
      "Iteration 23/50\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': None\n",
      "Reward (R² Score): 0.8921\n",
      "\n",
      "Iteration 24/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 5\n",
      "Reward (R² Score): 0.8625\n",
      "\n",
      "Iteration 25/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 4\n",
      "Reward (R² Score): 0.8921\n",
      "\n",
      "Iteration 26/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 50\n",
      "Reward (R² Score): 0.8884\n",
      "\n",
      "Iteration 27/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 10\n",
      "Reward (R² Score): 0.8909\n",
      "\n",
      "Iteration 28/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 16\n",
      "Reward (R² Score): 0.8817\n",
      "\n",
      "Iteration 29/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 4\n",
      "Reward (R² Score): 0.8921\n",
      "\n",
      "Iteration 30/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 170\n",
      "Reward (R² Score): 0.8927\n",
      "New Best R² Score: 0.8927 with Parameters: {'n_estimators': 170, 'max_depth': 20, 'min_samples_split': 4, 'max_features': None}\n",
      "\n",
      "Iteration 31/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 270\n",
      "Reward (R² Score): 0.8918\n",
      "\n",
      "Iteration 32/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 290\n",
      "Reward (R² Score): 0.8922\n",
      "\n",
      "Iteration 33/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 200\n",
      "Reward (R² Score): 0.8920\n",
      "\n",
      "Iteration 34/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 20\n",
      "Reward (R² Score): 0.8773\n",
      "\n",
      "Iteration 35/50\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': None\n",
      "Reward (R² Score): 0.8927\n",
      "\n",
      "Iteration 36/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 12\n",
      "Reward (R² Score): 0.8852\n",
      "\n",
      "Iteration 37/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 15\n",
      "Reward (R² Score): 0.8931\n",
      "New Best R² Score: 0.8931 with Parameters: {'n_estimators': 170, 'max_depth': 15, 'min_samples_split': 4, 'max_features': None}\n",
      "\n",
      "Iteration 38/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 25\n",
      "Reward (R² Score): 0.8916\n",
      "\n",
      "Iteration 39/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 200\n",
      "Reward (R² Score): 0.8928\n",
      "\n",
      "Iteration 40/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 30\n",
      "Reward (R² Score): 0.8916\n",
      "\n",
      "Iteration 41/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 5\n",
      "Reward (R² Score): 0.8613\n",
      "\n",
      "Iteration 42/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 35\n",
      "Reward (R² Score): 0.8916\n",
      "\n",
      "Iteration 43/50\n",
      "Adjusted Hyperparameter: max_features\n",
      "Chosen Value for 'max_features': None\n",
      "Reward (R² Score): 0.8931\n",
      "\n",
      "Iteration 44/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 90\n",
      "Reward (R² Score): 0.8942\n",
      "New Best R² Score: 0.8942 with Parameters: {'n_estimators': 90, 'max_depth': 15, 'min_samples_split': 4, 'max_features': None}\n",
      "\n",
      "Iteration 45/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 70\n",
      "Reward (R² Score): 0.8916\n",
      "\n",
      "Iteration 46/50\n",
      "Adjusted Hyperparameter: min_samples_split\n",
      "Chosen Value for 'min_samples_split': 16\n",
      "Reward (R² Score): 0.8825\n",
      "\n",
      "Iteration 47/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 140\n",
      "Reward (R² Score): 0.8921\n",
      "\n",
      "Iteration 48/50\n",
      "Adjusted Hyperparameter: n_estimators\n",
      "Chosen Value for 'n_estimators': 70\n",
      "Reward (R² Score): 0.8916\n",
      "\n",
      "Iteration 49/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 20\n",
      "Reward (R² Score): 0.8926\n",
      "\n",
      "Iteration 50/50\n",
      "Adjusted Hyperparameter: max_depth\n",
      "Chosen Value for 'max_depth': 20\n",
      "Reward (R² Score): 0.8926\n",
      "\n",
      "Best Hyperparameters Found:\n",
      "{'n_estimators': 90, 'max_depth': 15, 'min_samples_split': 4, 'max_features': None}\n",
      "Best Validation R² Score: 0.8942\n",
      "\n",
      "Final Predictions vs. Actual Values:\n",
      "    Actual      Predicted\n",
      "0   154500  140825.175299\n",
      "1   325000  326133.348792\n",
      "2   115000  117352.675132\n",
      "3   159000  161562.106173\n",
      "4   315500  318843.850238\n",
      "5    75500   84049.258466\n",
      "6   311500  214024.810318\n",
      "7   146000  151936.044863\n",
      "8    84500   84474.011376\n",
      "9   135500  127864.681582\n",
      "10  145000  159145.641270\n",
      "11  130000  122252.367002\n",
      "12   81000  109716.679407\n",
      "13  214000  207857.160345\n",
      "14  181000  178694.785901\n",
      "15  134500  130320.401544\n",
      "16  183500  193441.157568\n",
      "17  135000  135496.068527\n",
      "18  118400  116647.258377\n",
      "19  226000  206894.708384\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define the EXP3 algorithm class\n",
    "class EXP3:\n",
    "    def __init__(self, n_arms, gamma=0.1):\n",
    "        self.n_arms = n_arms\n",
    "        self.gamma = gamma\n",
    "        self.weights = np.ones(n_arms)\n",
    "        \n",
    "    def select_arm(self):\n",
    "        total_weight = np.sum(self.weights)\n",
    "        probabilities = (\n",
    "            (1 - self.gamma) * (self.weights / total_weight) +\n",
    "            (self.gamma / self.n_arms)\n",
    "        )\n",
    "        arm = np.random.choice(self.n_arms, p=probabilities)\n",
    "        return arm, probabilities\n",
    "        \n",
    "    def update(self, chosen_arm, reward, probabilities):\n",
    "        x = reward / probabilities[chosen_arm]\n",
    "        self.weights[chosen_arm] *= np.exp((self.gamma * x) / self.n_arms)\n",
    "\n",
    "# Load the House Prices dataset\n",
    "data = pd.read_csv('train2.csv')\n",
    "\n",
    "# Preprocessing steps\n",
    "# Drop columns with too many missing values or irrelevant features\n",
    "data = data.drop(['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu'], axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('SalePrice', axis=1)\n",
    "y = data['SalePrice']\n",
    "\n",
    "# Handle missing values\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Impute numerical features with median\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "X[numeric_features] = imputer_num.fit_transform(X[numeric_features])\n",
    "\n",
    "# Impute categorical features with mode\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_features] = imputer_cat.fit_transform(X[categorical_features])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the possible values for each hyperparameter with expanded search space\n",
    "hyperparameter_values = {\n",
    "    'n_estimators': list(range(50, 301, 10)),  # [50, 60, ..., 300]\n",
    "    'max_depth': [None] + list(range(5, 36, 5)),  # [None, 5, 10, ..., 35]\n",
    "    'min_samples_split': list(range(2, 21, 2)),  # [2, 4, ..., 20]\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Initialize current hyperparameter values (starting point)\n",
    "current_params = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_split': 2,\n",
    "    'max_features': None\n",
    "}\n",
    "\n",
    "# **New Section: Train and Evaluate the Initial Model**\n",
    "# Train the Random Forest model with the initial hyperparameters\n",
    "initial_model = RandomForestRegressor(\n",
    "    n_estimators=current_params['n_estimators'],\n",
    "    max_depth=current_params['max_depth'],\n",
    "    min_samples_split=current_params['min_samples_split'],\n",
    "    max_features=current_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "initial_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the initial model on the validation set\n",
    "initial_y_pred = initial_model.predict(X_valid)\n",
    "initial_r2 = r2_score(y_valid, initial_y_pred)\n",
    "print(f\"Initial Model R² Score (Before Tuning): {initial_r2:.4f}\")\n",
    "\n",
    "# Number of iterations for the hyperparameter tuning loop\n",
    "n_iterations = 50\n",
    "\n",
    "# Initialize the bandit algorithms for each hyperparameter\n",
    "bandits = {}\n",
    "for hp in hyperparameter_values:\n",
    "    n_arms = len(hyperparameter_values[hp])\n",
    "    bandits[hp] = {\n",
    "        'algorithm': EXP3(n_arms)\n",
    "    }\n",
    "\n",
    "# Initialize the bandit algorithm for hyperparameter selection\n",
    "hyperparameters = list(hyperparameter_values.keys())\n",
    "n_hyperparameters = len(hyperparameters)\n",
    "hyperparameter_bandit = EXP3(n_hyperparameters)\n",
    "\n",
    "# Map hyperparameter indices to names\n",
    "hyperparameter_indices = {idx: hp for idx, hp in enumerate(hyperparameters)}\n",
    "\n",
    "# Track the best model performance and parameters\n",
    "best_r2 = initial_r2  # Start with the initial R² score\n",
    "best_params = current_params.copy()\n",
    "\n",
    "# Hyperparameter tuning loop\n",
    "for i in range(n_iterations):\n",
    "    print(f\"\\nIteration {i+1}/{n_iterations}\")\n",
    "    \n",
    "    # Select which hyperparameter to adjust using the hyperparameter bandit\n",
    "    hp_arm_index, hp_probabilities = hyperparameter_bandit.select_arm()\n",
    "    hp_to_adjust = hyperparameter_indices[hp_arm_index]\n",
    "    \n",
    "    # Select the value for the chosen hyperparameter using its bandit algorithm\n",
    "    algorithm = bandits[hp_to_adjust]['algorithm']\n",
    "    arm_index, probabilities = algorithm.select_arm()\n",
    "    hp_value = hyperparameter_values[hp_to_adjust][arm_index]\n",
    "    \n",
    "    # Save the previous value to revert if necessary\n",
    "    previous_value = current_params[hp_to_adjust]\n",
    "    \n",
    "    # Update the current parameters with the new value\n",
    "    current_params[hp_to_adjust] = hp_value\n",
    "    \n",
    "    # Train the Random Forest model with the updated hyperparameters\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=current_params['n_estimators'],\n",
    "        max_depth=current_params['max_depth'],\n",
    "        min_samples_split=current_params['min_samples_split'],\n",
    "        max_features=current_params['max_features'],\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "    reward = r2  # Use R² score as the reward\n",
    "\n",
    "    # Update the bandit algorithm for the chosen hyperparameter value\n",
    "    algorithm.update(arm_index, reward, probabilities)\n",
    "    \n",
    "    # Update the hyperparameter selection bandit\n",
    "    hyperparameter_bandit.update(hp_arm_index, reward, hp_probabilities)\n",
    "    \n",
    "    # Print detailed output\n",
    "    print(f\"Adjusted Hyperparameter: {hp_to_adjust}\")\n",
    "    print(f\"Chosen Value for '{hp_to_adjust}': {hp_value}\")\n",
    "    print(f\"Reward (R² Score): {reward:.4f}\")\n",
    "    \n",
    "    # Check if the new configuration is better\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_params = current_params.copy()\n",
    "        print(f\"New Best R² Score: {best_r2:.4f} with Parameters: {best_params}\")\n",
    "    else:\n",
    "        # If not better, revert the hyperparameter change\n",
    "        current_params[hp_to_adjust] = previous_value\n",
    "\n",
    "# After the tuning loop, print the best hyperparameters and R² score\n",
    "print(\"\\nBest Hyperparameters Found:\")\n",
    "print(best_params)\n",
    "print(f\"Best Validation R² Score: {best_r2:.4f}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    max_features=best_params['max_features'],\n",
    "    random_state=42\n",
    ")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "final_predictions = final_model.predict(X_valid)\n",
    "\n",
    "# Compare final predictions with actual values\n",
    "final_comparison_df = pd.DataFrame({'Actual': y_valid.values, 'Predicted': final_predictions})\n",
    "print(\"\\nFinal Predictions vs. Actual Values:\")\n",
    "print(final_comparison_df.head(20))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
